<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hadoop,Spark,闲聊," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="面试回来之后把其中比较重要的问题记了下来写了个总结：（答案在后面）
1、简答说一下hadoop的map-reduce编程模型
2、hadoop的TextInputFormat作用是什么，如何自定义实现
3、hadoop和spark的都是并行计算，那么他们有什么相同和区别
4、为什么要用flume导入hdfs，hdfs的构架是怎样的
5、map-reduce程序运行的时候会有什么比较常见的问题
6、">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop/Spark相关面试问题总结">
<meta property="og:url" content="http://xiaohei.info/2015/07/16/hadoop-spark-interview/index.html">
<meta property="og:site_name" content="小黑的博客">
<meta property="og:description" content="面试回来之后把其中比较重要的问题记了下来写了个总结：（答案在后面）
1、简答说一下hadoop的map-reduce编程模型
2、hadoop的TextInputFormat作用是什么，如何自定义实现
3、hadoop和spark的都是并行计算，那么他们有什么相同和区别
4、为什么要用flume导入hdfs，hdfs的构架是怎样的
5、map-reduce程序运行的时候会有什么比较常见的问题
6、">
<meta property="og:updated_time" content="2016-07-15T02:34:55.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop/Spark相关面试问题总结">
<meta name="twitter:description" content="面试回来之后把其中比较重要的问题记了下来写了个总结：（答案在后面）
1、简答说一下hadoop的map-reduce编程模型
2、hadoop的TextInputFormat作用是什么，如何自定义实现
3、hadoop和spark的都是并行计算，那么他们有什么相同和区别
4、为什么要用flume导入hdfs，hdfs的构架是怎样的
5、map-reduce程序运行的时候会有什么比较常见的问题
6、">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://xiaohei.info/2015/07/16/hadoop-spark-interview/"/>

  <title> Hadoop/Spark相关面试问题总结 | 小黑的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?077978704bc099796a03e532724e1e70";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小黑的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">大数据研发和云计算技术</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resume">
          <a href="/resume" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            menu.resume
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Hadoop/Spark相关面试问题总结
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2015-07-16T10:34:15+08:00" content="2015-07-16">
              2015-07-16
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2015/07/16/hadoop-spark-interview/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2015/07/16/hadoop-spark-interview/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2015/07/16/hadoop-spark-interview/" class="leancloud_visitors" data-flag-title="Hadoop/Spark相关面试问题总结">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>面试回来之后把其中比较重要的问题记了下来写了个总结：<br>（答案在后面）</p>
<p>1、简答说一下hadoop的map-reduce编程模型</p>
<p>2、hadoop的TextInputFormat作用是什么，如何自定义实现</p>
<p>3、hadoop和spark的都是并行计算，那么他们有什么相同和区别</p>
<p>4、为什么要用flume导入hdfs，hdfs的构架是怎样的</p>
<p>5、map-reduce程序运行的时候会有什么比较常见的问题</p>
<p>6、简单说一下hadoop和spark的shuffle过程</p>
<p>以下是自己的理解，如果有不对的地方希望各位大侠可以帮我指出来~：</p>
<p><strong>1、简答说一下hadoop的map-reduce编程模型</strong></p>
<p>首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合</p>
<p>使用的是hadoop内置的数据类型，比如longwritable、text等</p>
<p>将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value在输出</p>
<p>之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区规则</p>
<p>之后会对key进行进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则</p>
<p>之后进行一个combiner归约操作，其实就是一个本地段的reduce预处理，以减小后面shufle和reducer的工作量</p>
<p>reduce task会通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job</p>
<p><strong>2、hadoop的TextInputFormat作用是什么，如何自定义实现</strong></p>
<p>InputFormat会在map操作之前对数据进行两方面的预处理<br>1是getSplits，返回的是InputSplit数组，对数据进行split分片，每片交给map操作一次<br>2是getRecordReader，返回的是RecordReader对象，对每个split分片进行转换为key-value键值对格式传递给map</p>
<p>常用的InputFormat是TextInputFormat，使用的是LineRecordReader对每个分片进行键值对的转换，以行偏移量作为键，行内容作为值</p>
<p>自定义类继承InputFormat接口，重写createRecordReader和isSplitable方法<br>在createRecordReader中可以自定义分隔符</p>
<p><strong>3、hadoop和spark的都是并行计算，那么他们有什么相同和区别</strong></p>
<p>两者都是用mr模型来进行并行计算，hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束</p>
<p>spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job</p>
<p>这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算</p>
<p>hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系</p>
<p>spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错</p>
<p><strong>4、为什么要用flume导入hdfs，hdfs的构架是怎样的</strong></p>
<p>flume可以实时的导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候会形成一个文件，或者超过指定时间的话也形成一个文件</p>
<p>文件都是存储在datanode上面的，namenode记录着datanode的元数据信息，而namenode的元数据信息是存在内存中的，所以当文件切片很小或者很多的时候会卡死</p>
<p><strong>5、map-reduce程序运行的时候会有什么比较常见的问题</strong></p>
<p>比如说作业中大部分都完成了，但是总有几个reduce一直在运行</p>
<p>这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是因为对键值对任务划分的不均匀造成的数据倾斜</p>
<p>解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作</p>
<p><strong>6、简单说一下hadoop和spark的shuffle过程</strong></p>
<p>hadoop：map端保存分片数据，通过网络收集到reduce端<br>spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor</p>
<p>减少shuffle可以提高性能</p>
<p>部分答案不是十分准确欢迎补充:-)</p>
<p>——-补充更新———</p>
<p><strong>1、Hive中存放是什么？</strong><br>表。<br>存的是和hdfs的映射关系，hive是逻辑上的数据仓库，实际操作的都是hdfs上的文件，HQL就是用sql语法来写的mr程序。</p>
<p><strong>2、Hive与关系型数据库的关系？</strong><br>没有关系，hive是数据仓库，不能和数据库一样进行实时的CURD操作。<br>是一次写入多次读取的操作，可以看成是ETL工具。</p>
<p><strong>3、Flume工作机制是什么？</strong><br>核心概念是agent，里面包括source、chanel和sink三个组件。<br>source运行在日志收集节点进行日志采集，之后临时存储在chanel中，sink负责将chanel中的数据发送到目的地。<br>只有成功发送之后chanel中的数据才会被删除。<br>首先书写flume配置文件，定义agent、source、chanel和sink然后将其组装，执行flume-ng命令。</p>
<p><strong>4、Sqoop工作原理是什么？</strong><br>hadoop生态圈上的数据传输工具。<br>可以将关系型数据库的数据导入非结构化的hdfs、hive或者bbase中，也可以将hdfs中的数据导出到关系型数据库或者文本文件中。<br>使用的是mr程序来执行任务，使用jdbc和关系型数据库进行交互。<br>import原理：通过指定的分隔符进行数据切分，将分片传入各个map中，在map任务中在每行数据进行写入处理没有reduce。<br>export原理：根据要操作的表名生成一个java类，并读取其元数据信息和分隔符对非结构化的数据进行匹配，多个map作业同时执行写入关系型数据库</p>
<p><strong>5、Hbase行健列族的概念，物理模型，表的设计原则？</strong><br>行健：是hbase表自带的，每个行健对应一条数据。<br>列族：是创建表时指定的，为列的集合，每个列族作为一个文件单独存储，存储的数据都是字节数组，其中的数据可以有很多，通过时间戳来区分。<br>物理模型：整个hbase表会拆分为多个region，每个region记录着行健的起始点保存在不同的节点上，查询时就是对各个节点的并行查询，当region很大时使用.META表存储各个region的起始点，-ROOT又可以存储.META的起始点。<br>rowkey的设计原则：各个列簇数据平衡，长度原则、相邻原则，创建表的时候设置表放入regionserver缓存中，避免自动增长和时间，使用字节数组代替string，最大长度64kb，最好16字节以内，按天分表，两个字节散列，四个字节存储时分毫秒。<br>列族的设计原则：尽可能少（按照列族进行存储，按照region进行读取，不必要的io操作），经常和不经常使用的两类数据放入不同列族中，列族名字尽可能短。</p>
<p><strong>6、Spark Streaming和Storm有何区别？</strong><br>一个实时毫秒一个准实时亚秒，不过storm的吞吐率比较低。</p>
<p><strong>7、mllib支持的算法？</strong><br>大体分为四大类，分类、聚类、回归、协同过滤。</p>
<p><strong>8、简答说一下hadoop的map-reduce编程模型？</strong><br>首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合。<br>将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value在输出。<br>之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区规则。<br>之后会对key进行进行sort排序，grouping分组操作将相同key的value合并分组输出。<br>在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则。<br>之后进行一个combiner归约操作，其实就是一个本地段的reduce预处理，以减小后面shufle和reducer的工作量。<br>reduce task会通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job。</p>
<p><strong>9、Hadoop平台集群配置、环境变量设置？</strong><br>zookeeper：修改zoo.cfg文件，配置dataDir，和各个zk节点的server地址端口，tickTime心跳时间默认是2000ms，其他超时的时间都是以这个为基础的整数倍，之后再dataDir对应目录下写入myid文件和zoo.cfg中的server相对应。</p>
<p>hadoop：修改<br>hadoop-env.sh配置java环境变量<br>core-site.xml配置zk地址，临时目录等<br>hdfs-site.xml配置nn信息，rpc和http通信地址，nn自动切换、zk连接超时时间等<br>yarn-site.xml配置resourcemanager地址<br>mapred-site.xml配置使用yarn<br>slaves配置节点信息<br>格式化nn和zk。</p>
<p>hbase：修改<br>hbase-env.sh配置java环境变量和是否使用自带的zk<br>hbase-site.xml配置hdfs上数据存放路径，zk地址和通讯超时时间、master节点<br>regionservers配置各个region节点<br>zoo.cfg拷贝到conf目录下</p>
<p>spark：<br>安装Scala<br>修改spark-env.sh配置环境变量和master和worker节点配置信息</p>
<p>环境变量的设置：直接在/etc/profile中配置安装的路径即可，或者在当前用户的宿主目录下，配置在.bashrc文件中，该文件不用source重新打开shell窗口即可，配置在.bash_profile的话只对当前用户有效。</p>
<p><strong>10、Hadoop性能调优？</strong></p>
<p>调优可以通过系统配置、程序编写和作业调度算法来进行。<br>hdfs的block.size可以调到128/256（网络很好的情况下，默认为64）<br>调优的大头：mapred.map.tasks、mapred.reduce.tasks设置mr任务数（默认都是1）<br>mapred.tasktracker.map.tasks.maximum每台机器上的最大map任务数<br>mapred.tasktracker.reduce.tasks.maximum每台机器上的最大reduce任务数<br>mapred.reduce.slowstart.completed.maps配置reduce任务在map任务完成到百分之几的时候开始进入<br>这个几个参数要看实际节点的情况进行配置，reduce任务是在33%的时候完成copy，要在这之前完成map任务，（map可以提前完成）<br>mapred.compress.map.output,mapred.output.compress配置压缩项，消耗cpu提升网络和磁盘io<br>合理利用combiner<br>注意重用writable对象</p>
<p><strong>11、Hadoop高并发？</strong><br>首先肯定要保证集群的高可靠性，在高并发的情况下不会挂掉，支撑不住可以通过横向扩展。<br>datanode挂掉了使用hadoop脚本重新启动。</p>
<p><strong>12、hadoop的TextInputFormat作用是什么，如何自定义实现？</strong><br>InputFormat会在map操作之前对数据进行两方面的预处理。<br>1是getSplits，返回的是InputSplit数组，对数据进行split分片，每片交给map操作一次 。<br>2是getRecordReader，返回的是RecordReader对象，对每个split分片进行转换为key-value键值对格式传递给map。<br>常用的InputFormat是TextInputFormat，使用的是LineRecordReader对每个分片进行键值对的转换，以行偏移量作为键，行内容作为值。<br>自定义类继承InputFormat接口，重写createRecordReader和isSplitable方法 。<br>在createRecordReader中可以自定义分隔符。</p>
<p><strong>13、hadoop和spark的都是并行计算，那么他们有什么相同和区别？</strong><br>两者都是用mr模型来进行并行计算，hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束。<br>spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job。<br>这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算。<br>hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系。<br>spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错。</p>
<p><strong>14、为什么要用flume导入hdfs，hdfs的构架是怎样的？</strong><br>flume可以实时的导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候会形成一个文件，或者超过指定时间的话也形成一个文件。<br>文件都是存储在datanode上面的，namenode记录着datanode的元数据信息，而namenode的元数据信息是存在内存中的，所以当文件切片很小或者很多的时候会卡死。</p>
<p><strong>15、map-reduce程序运行的时候会有什么比较常见的问题？</strong><br>比如说作业中大部分都完成了，但是总有几个reduce一直在运行。<br>这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是因为对键值对任务划分的不均匀造成的数据倾斜。<br>解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作。</p>
<p><strong>16、简单说一下hadoop和spark的shuffle过程？</strong><br>hadoop：map端保存分片数据，通过网络收集到reduce端。<br>spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor。<br>减少shuffle可以提高性能。</p>
<p><strong>17、RDD机制？</strong><br>rdd分布式弹性数据集，简单的理解成一种数据结构，是spark框架上的通用货币。<br>所有算子都是基于rdd来执行的，不同的场景会有不同的rdd实现类，但是都可以进行互相转换。<br>rdd执行过程中会形成dag图，然后形成lineage保证容错性等。<br>从物理的角度来看rdd存储的是block和node之间的映射。</p>
<p><strong>18、spark有哪些组件？</strong><br>（1）master：管理集群和节点，不参与计算。<br>（2）worker：计算节点，进程本身不参与计算，和master汇报。<br>（3）Driver：运行程序的main方法，创建spark context对象。<br>（4）spark context：控制整个application的生命周期，包括dagsheduler和task scheduler等组件。<br>（5）client：用户提交程序的入口。</p>
<p><strong>19、spark工作机制？</strong><br>用户在client端提交作业后，会由Driver运行main方法并创建spark context上下文。<br>执行add算子，形成dag图输入dagscheduler，按照add之间的依赖关系划分stage输入task scheduler。<br>task scheduler会将stage划分为task set分发到各个节点的executor中执行。</p>
<p><strong>20、spark的优化怎么做？</strong><br>通过spark-env文件、程序中sparkconf和set property设置。<br>（1）计算量大，形成的lineage过大应该给已经缓存了的rdd添加checkpoint，以减少容错带来的开销。<br>（2）小分区合并，过小的分区造成过多的切换任务开销，使用repartition。</p>
<p><strong>21、kafka工作原理？</strong><br>producer向broker发送事件，consumer从broker消费事件。<br>事件由topic区分开，每个consumer都会属于一个group。<br>相同group中的consumer不能重复消费事件，而同一事件将会发送给每个不同group的consumer。</p>
<p><strong>22、ALS算法原理？</strong><br>答：对于user-product-rating数据，als会建立一个稀疏的评分矩阵，其目的就是通过一定的规则填满这个稀疏矩阵。<br>als会对稀疏矩阵进行分解，分为用户-特征值，产品-特征值，一个用户对一个产品的评分可以由这两个矩阵相乘得到。<br>通过固定一个未知的特征值，计算另外一个特征值，然后交替反复进行最小二乘法，直至差平方和最小，即可得想要的矩阵。</p>
<p><strong>23、kmeans算法原理？</strong><br>随机初始化中心点范围，计算各个类别的平均值得到新的中心点。<br>重新计算各个点到中心值的距离划分，再次计算平均值得到新的中心点，直至各个类别数据平均值无变化。</p>
<p><strong>24、canopy算法原理？</strong><br>根据两个阈值来划分数据，以随机的一个数据点作为canopy中心。<br>计算其他数据点到其的距离，划入t1、t2中，划入t2的从数据集中删除，划入t1的其他数据点继续计算，直至数据集中无数据。</p>
<p><strong>25、朴素贝叶斯分类算法原理？</strong><br>对于待分类的数据和分类项，根据待分类数据的各个特征属性，出现在各个分类项中的概率判断该数据是属于哪个类别的。</p>
<p><strong>26、关联规则挖掘算法apriori原理？</strong><br>一个频繁项集的子集也是频繁项集，针对数据得出每个产品的支持数列表，过滤支持数小于预设值的项，对剩下的项进行全排列，重新计算支持数，再次过滤，重复至全排列结束，可得到频繁项和对应的支持数。</p>
<p>作者：<a href="http://www.xiaohei.info" target="_blank" rel="external">@小黑</a></p>
<p>以下是自己的理解，如果有不对的地方希望各位大侠可以帮我指出来~：</p>
<p><strong>1、简答说一下hadoop的map-reduce编程模型</strong></p>
<p>首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合</p>
<p>使用的是hadoop内置的数据类型，比如longwritable、text等</p>
<p>将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value在输出</p>
<p>之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区规则</p>
<p>之后会对key进行进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则</p>
<p>之后进行一个combiner归约操作，其实就是一个本地段的reduce预处理，以减小后面shufle和reducer的工作量</p>
<p>reduce task会通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job</p>
<p><strong>2、hadoop的TextInputFormat作用是什么，如何自定义实现</strong></p>
<p>InputFormat会在map操作之前对数据进行两方面的预处理<br>1是getSplits，返回的是InputSplit数组，对数据进行split分片，每片交给map操作一次<br>2是getRecordReader，返回的是RecordReader对象，对每个split分片进行转换为key-value键值对格式传递给map</p>
<p>常用的InputFormat是TextInputFormat，使用的是LineRecordReader对每个分片进行键值对的转换，以行偏移量作为键，行内容作为值</p>
<p>自定义类继承InputFormat接口，重写createRecordReader和isSplitable方法<br>在createRecordReader中可以自定义分隔符</p>
<p><strong>3、hadoop和spark的都是并行计算，那么他们有什么相同和区别</strong></p>
<p>两者都是用mr模型来进行并行计算，hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束</p>
<p>spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job</p>
<p>这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算</p>
<p>hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系</p>
<p>spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错</p>
<p><strong>4、为什么要用flume导入hdfs，hdfs的构架是怎样的</strong></p>
<p>flume可以实时的导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候会形成一个文件，或者超过指定时间的话也形成一个文件</p>
<p>文件都是存储在datanode上面的，namenode记录着datanode的元数据信息，而namenode的元数据信息是存在内存中的，所以当文件切片很小或者很多的时候会卡死</p>
<p><strong>5、map-reduce程序运行的时候会有什么比较常见的问题</strong></p>
<p>比如说作业中大部分都完成了，但是总有几个reduce一直在运行</p>
<p>这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是因为对键值对任务划分的不均匀造成的数据倾斜</p>
<p>解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作</p>
<p><strong>6、简单说一下hadoop和spark的shuffle过程</strong></p>
<p>hadoop：map端保存分片数据，通过网络收集到reduce端<br>spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor</p>
<p>减少shuffle可以提高性能</p>
<p>部分答案不是十分准确欢迎补充:-)</p>
<p>作者：<a href="http://www.xiaohei.info" target="_blank" rel="external">@小黑</a></p>

      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/gzh.jpg" alt="小黑 wechat" style="width: 200px; max-width: 100%;"/>
    <div>Warning：能不用微信扫就不用微信扫</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>Out Of Memory Error：千万别点！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/weixin.png" alt="小黑 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/alipay.jpg" alt="小黑 Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag">#Hadoop</a>
          
            <a href="/tags/Spark/" rel="tag">#Spark</a>
          
            <a href="/tags/闲聊/" rel="tag">#闲聊</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/07/04/scala-sort/" rel="next" title="Scala实现冒泡排序、归并排序和快速排序">
                <i class="fa fa-chevron-left"></i> Scala实现冒泡排序、归并排序和快速排序
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/08/05/kafka-base-info/" rel="prev" title="初识Kafka：构架、生产消费模型以及其他相关概念">
                初识Kafka：构架、生产消费模型以及其他相关概念 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2015/07/16/hadoop-spark-interview/"
           data-title="Hadoop/Spark相关面试问题总结" data-url="http://xiaohei.info/2015/07/16/hadoop-spark-interview/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="小黑" />
          <p class="site-author-name" itemprop="name">小黑</p>
          <p class="site-description motion-element" itemprop="description">臭打字的</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">87</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/chubbyjiang" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/xiaoheiinfo" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <p class="post-toc-empty">此文章未包含目录</p>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2014 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小黑</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"xiaoheiinfo"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  

  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("OoGPuTjuKRn43jP9DILK5sqs-gzGzoHsz", "KDn8G4yvtw7FA7WKGQjYK0RR");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
